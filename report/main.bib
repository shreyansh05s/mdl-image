@techreport{Krizhevsky09learningmultiple,
  author      = {Alex Krizhevsky},
  title       = {Learning multiple layers of features from tiny images},
  institution = {},
  year        = {2009}
}


@misc{wandb,
  title  = {Experiment Tracking with Weights and Biases},
  year   = {2020},
  note   = {Software available from wandb.com},
  url    = {https://www.wandb.com/},
  author = {Biewald, Lukas}
}

@incollection{NEURIPS2019_9015,
  title     = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
  author    = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
  booktitle = {Advances in Neural Information Processing Systems 32},
  pages     = {8024--8035},
  year      = {2019},
  publisher = {Curran Associates, Inc.},
  url       = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}
} 

@article{DBLP:journals/corr/abs-2103-14030,
  author     = {Ze Liu and
                Yutong Lin and
                Yue Cao and
                Han Hu and
                Yixuan Wei and
                Zheng Zhang and
                Stephen Lin and
                Baining Guo},
  title      = {Swin Transformer: Hierarchical Vision Transformer using Shifted Windows},
  journal    = {CoRR},
  volume     = {abs/2103.14030},
  year       = {2021},
  url        = {https://arxiv.org/abs/2103.14030},
  eprinttype = {arXiv},
  eprint     = {2103.14030},
  timestamp  = {Thu, 08 Apr 2021 07:53:26 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-2103-14030.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{deng2009imagenet,
  title        = {Imagenet: A large-scale hierarchical image database},
  author       = {Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle    = {2009 IEEE conference on computer vision and pattern recognition},
  pages        = {248--255},
  year         = {2009},
  organization = {Ieee}
}

@misc{wu2020visual,
  title         = {Visual Transformers: Token-based Image Representation and Processing for Computer Vision},
  author        = {Bichen Wu and Chenfeng Xu and Xiaoliang Dai and Alvin Wan and Peizhao Zhang and Zhicheng Yan and Masayoshi Tomizuka and Joseph Gonzalez and Kurt Keutzer and Peter Vajda},
  year          = {2020},
  eprint        = {2006.03677},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@inproceedings{he2016deep,
  title     = {Deep residual learning for image recognition},
  author    = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages     = {770--778},
  year      = {2016}
}

@article{DBLP:journals/corr/abs-2010-11929,
  author     = {Alexey Dosovitskiy and
                Lucas Beyer and
                Alexander Kolesnikov and
                Dirk Weissenborn and
                Xiaohua Zhai and
                Thomas Unterthiner and
                Mostafa Dehghani and
                Matthias Minderer and
                Georg Heigold and
                Sylvain Gelly and
                Jakob Uszkoreit and
                Neil Houlsby},
  title      = {An Image is Worth 16x16 Words: Transformers for Image Recognition
                at Scale},
  journal    = {CoRR},
  volume     = {abs/2010.11929},
  year       = {2020},
  url        = {https://arxiv.org/abs/2010.11929},
  eprinttype = {arXiv},
  eprint     = {2010.11929},
  timestamp  = {Fri, 20 Nov 2020 14:04:05 +0100},
  biburl     = {https://dblp.org/rec/journals/corr/abs-2010-11929.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2010-01412,
  author     = {Pierre Foret and
                Ariel Kleiner and
                Hossein Mobahi and
                Behnam Neyshabur},
  title      = {Sharpness-Aware Minimization for Efficiently Improving Generalization},
  journal    = {CoRR},
  volume     = {abs/2010.01412},
  year       = {2020},
  url        = {https://arxiv.org/abs/2010.01412},
  eprinttype = {arXiv},
  eprint     = {2010.01412},
  timestamp  = {Mon, 12 Oct 2020 17:53:10 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-2010-01412.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{Kingma2014AdamAM,
  title   = {Adam: A Method for Stochastic Optimization},
  author  = {Diederik P. Kingma and Jimmy Ba},
  journal = {CoRR},
  year    = {2014},
  volume  = {abs/1412.6980}
}

@inproceedings{wolf-etal-2020-transformers,
  title     = {Transformers: State-of-the-Art Natural Language Processing},
  author    = {Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and RÃ©mi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush},
  booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations},
  month     = oct,
  year      = {2020},
  address   = {Online},
  publisher = {Association for Computational Linguistics},
  url       = {https://www.aclweb.org/anthology/2020.emnlp-demos.6},
  pages     = {38--45}
}

@misc{vit-pretrained,
  title        = {{VIT - finetuned model for CIFAR-100. Pretrained on Imagenet 21K}},
  howpublished = {\url{https://huggingface.co/Ahmed9275/Vit-Cifar100}},
  author       = {Ahmed9275},
  note         = {Accessed: 2023-04-22}
}

@misc{swin-pretrained,
  title        = {{SWIN - finetuned model for CIFAR-100. Pretrained on Imagenet 1K}},
  howpublished = {\url{https://huggingface.co/MazenAmria/swin-small-finetuned-cifar100}},
  author       = {MazenAmria},
  note         = {Accessed: 2023-04-22}
}

@misc{cifar-100-leaderboard,
  title        = {{Huggingface Leaderboard for CIFAR-100 models}},
  howpublished = {\url{https://huggingface.co/spaces/autoevaluate/leaderboards?dataset=cifar100&only_verified=0&task=-any-&config=-unspecified-&split=-unspecified-&metric=accuracy}},
  author       = {Huggingface},
  note         = {Accessed: 2023-04-22}
}

@misc{paperswithcode,
  title        = {{SOTA models: Their papers, code and history of usage}},
  howpublished = {\url{https://paperswithcode.com}},
  note         = {Accessed: 2023-04-22}
}


@misc{pytorch-cifar-model,
  title        = {{Pytorch hub pretrained CIFAR models}},
  howpublished = {\url{https://github.com/chenyaofo/pytorch-cifar-models/tree/master}},
  note         = {Accessed: 2023-04-22}
}

@article{DBLP:journals/corr/abs-2102-11600,
  author     = {Jungmin Kwon and
                Jeongseop Kim and
                Hyunseo Park and
                In Kwon Choi},
  title      = {{ASAM:} Adaptive Sharpness-Aware Minimization for Scale-Invariant
                Learning of Deep Neural Networks},
  journal    = {CoRR},
  volume     = {abs/2102.11600},
  year       = {2021},
  url        = {https://arxiv.org/abs/2102.11600},
  eprinttype = {arXiv},
  eprint     = {2102.11600},
  timestamp  = {Wed, 24 Feb 2021 15:42:45 +0100},
  biburl     = {https://dblp.org/rec/journals/corr/abs-2102-11600.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}